{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# upstage-ai-advanced-ir7 디렉토리의 경로를 생성합니다\n",
    "project_dir = os.path.join(os.getcwd(), 'upstage-ai-advanced-ir7')\n",
    "\n",
    "# 시스템 경로에 upstage-ai-advanced-ir7 디렉토리를 추가합니다\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tools.searchengine import SearchEngine\n",
    "from tools.query_transformer import QueryTransformer\n",
    "from tools.generate import Generate\n",
    "\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import gc\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vram():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "clean_vram()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수 설정\n",
    "load_dotenv('/upstage-ai-advanced-ir7/.env')\n",
    "upstage_api_key = os.getenv('UPSTAGE_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = upstage_api_key\n",
    "\n",
    "# 사용자 설정\n",
    "embedding_dim = 4096\n",
    "query_transformer_model_name = \"rtzr/ko-gemma-2-9b-it\"\n",
    "generate_model_name = \"rtzr/ko-gemma-2-9b-it\"\n",
    "faiss_path = '/upstage-ai-advanced-ir7/data/faiss_index.faiss'\n",
    "\n",
    "# tool 생성\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "search_engine = SearchEngine(embedding_dim, upstage_api_key, device)\n",
    "query_transformer = QueryTransformer(query_transformer_model_name, device)\n",
    "generator = Generate(generate_model_name, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index 생성 OR 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "elastic search client 생성중 ...\n",
      "\n",
      "elastic search client 생성 완료 ... \n",
      "\n",
      "faiss index load 중 ...\n",
      "\n",
      "faiss index load 완료!\n"
     ]
    }
   ],
   "source": [
    "with open(\"/upstage-ai-advanced-ir7/data/documents.jsonl\") as f:\n",
    "    docs = [json.loads(line) for line in f]\n",
    "\n",
    "# index 만들기 or 가져오기\n",
    "search_engine.create_elasticsearch_index(docs)\n",
    "search_engine.load_faiss_index(faiss_path, docs)\n",
    "clean_vram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "/opt/conda/envs/myvenv/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자연어 처리 기술의 음성 인식 능력에 대한 정보\n"
     ]
    }
   ],
   "source": [
    "prompt_input = input(\"무엇을 도와드릴까요?\")\n",
    "query = [{\"role\": 'user', \"content\": prompt_input}]\n",
    "\n",
    "chat_prompt = query_transformer.create_chat_prompt(query)\n",
    "standalone_query = query_transformer.generate_standalone_query(chat_prompt)\n",
    "clean_vram()\n",
    "print(standalone_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 관련 문서 검색(RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reranking 실행 시작 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_id': '123', 'standalone_query': '자연어 처리 기술의 음성 인식 능력에 대한 정보', 'topk': ['d1900d8f-e489-4922-973e-1d7b9729bcb1', 'f72070a4-124c-49a7-9871-68d9fe3ee469', 'e1c86893-206b-43d2-8900-b1dd40aeefa5'], 'references': [{'score': 0.05344495549798012, 'content': '노이즈 캔슬링 기기는 소리의 간섭을 사용하여 작동합니다. 간섭은 두 개 이상의 소리 파동이 만나면 발생하는 현상으로, 서로 반대 방향으로 진동하는 파동이 만나면 상쇄되어 소리가 사라지는 원리입니다. 노이즈 캔슬링 기기는 주변의 잡음을 감지하고, 그와 동일한 크기와 반대 방향으로 소리를 생성하여 상쇄시킵니다. 이를 통해 주변의 잡음을 효과적으로 제거하고, 조용한 환경을 조성할 수 있습니다. 노이즈 캔슬링 기기는 주로 항공기, 자동차, 헤드폰 등에서 사용되며, 사용자에게 편안하고 조용한 환경을 제공합니다.'}, {'score': 0.049043845385313034, 'content': '20.0 T 자기장에서 31P의 NMR 주파수는 345.0 MHz입니다. 핵자기공명(NMR)은 분자의 화학적 환경과 구조에 대한 정보를 제공하는 분광 기술입니다. NMR에서 핵이 공명하는 주파수는 핵이 노출되는 자기장의 세기에 따라 다릅니다. 이 경우 31P 핵은 20.0 T 자기장에 노출되어 345.0 MHz의 공명 주파수가 발생합니다. 이 정보는 과학자들이 분자의 특성과 행동을 자세히 연구할 수 있도록 해주기 때문에 화학, 생화학, 의학 연구 등 다양한 분야에서 가치가 있습니다.'}, {'score': 0.03491341322660446, 'content': 'DFA(Deterministic Finite Automaton)는 문자열의 패턴을 인식하는 데 사용되는 수학적 모델입니다. 이 경우 우리는 DFA가 언어 L을 인식하는 데 필요한 최소 상태 수를 찾는 데 관심이 있습니다. 여기서 L은 {0, 1}*의 문자열 집합입니다.\\n\\n주어진 조건 k >= 2를 생각해 봅시다. 이는 k가 2보다 크거나 같은 양의 정수임을 의미합니다.\\n\\nL을 인식하려면 문자열 x가 두 가지 조건을 만족하는 경우에만 L에 속하도록 해야 합니다.\\n1. x에 있는 0의 개수는 k로 나누어집니다.\\n2. x에 있는 1의 개수는 홀수입니다.\\n\\nL을 인식하는 DFA를 구성하려면 다음 단계를 수행하면 됩니다.\\n\\n1. 초기 상태 q0으로 시작합니다.\\n2. k개의 상태 q1, q2, ..., qk를 생성합니다. 이러한 상태는 지금까지 만난 0의 수(모듈로 k)를 나타냅니다.\\n3. qeven과 qodd라는 두 가지 추가 상태를 만듭니다. 이러한 상태는 지금까지 발견된 1의 수가 짝수인지 홀수인지를 나타냅니다.\\n4. q0을 초기 상태로 설정하고 qeven을 수용 상태로 설정합니다.\\n5. 각 상태 qi에 대해 0과 1 모두에 대해 다음 상태인 qi+1(모듈로 k)로의 전환을 만듭니다.\\n6. 각 상태 qi에 대해 지금까지 발생한 1 수의 패리티를 나타내는 다른 상태로 1에 대한 전환을 만듭니다. 예를 들어, qi가 짝수이면 1에서 qodd로의 전환을 생성하고 그 반대의 경우도 마찬가지입니다.\\n7. 모든 상태가 생성될 때까지 5단계와 6단계를 반복합니다.\\n8. 모든 전환이 정의되면 DFA가 완료됩니다.\\n\\n이 DFA에 필요한 최소 상태 수는 2,000개입니다. 지금까지 만난 0의 수를 추적하려면 k 상태가 필요하고, 지금까지 만난 1의 수에 대한 패리티를 추적하려면 2개의 상태(qeven 및 qodd)가 필요하기 때문입니다.\\n\\n따라서 문제의 답은 2k이다.'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_vram()\n",
    "eval_id = \"123\"\n",
    "query_data = [{\"eval_id\": eval_id, 'standalone_query': standalone_query}]\n",
    "result = search_engine.search_quries(query_data)[0]\n",
    "clean_vram()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 참조 문헌 2에 따르면 자연어 처리 기술의 음성 인식 능력에 대한 정보는 없습니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_vram()\n",
    "query = result['standalone_query']\n",
    "references = result['references']\n",
    "response = generator.generate_response(query, references)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
